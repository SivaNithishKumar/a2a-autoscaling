#!/usr/bin/env python3
"""Comprehensive test script for Infrastructure Monitoring Agent."""

import asyncio
import sys
import json
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))

print("ğŸ§ª INFRASTRUCTURE MONITORING AGENT - A2A TESTING SUITE")
print("============================================================")
print("ğŸ—ï¸ Testing Infrastructure Monitoring Agent for Production AI-Ops")
print("ğŸ¯ Focus: Anomaly detection and predictive analytics")
print()
print("="*60)


async def test_agent_initialization():
    """Test 1: Agent Initialization and Metrics Setup"""
    print("\nğŸ“¦ Test 1: Agent Initialization and Metrics Setup...")
    
    try:
        from multi_agent_a2a.agents.infrastructure_monitor.agent import InfrastructureMonitoringAgent, InfrastructureMonitoringExecutor
        
        # Test agent initialization
        agent = InfrastructureMonitoringAgent()
        
        print(f"âœ… Agent Name: {agent.name}")
        print(f"âœ… Monitored Services: {len(agent.monitored_services)}")
        print(f"âœ… Active Alerts: {len(agent.active_alerts)}")
        print(f"âœ… Prediction Model Accuracy: {agent.prediction_model_accuracy:.1%}")
        
        # Test agent skills
        skills = agent.get_skills()
        print(f"âœ… Skills Registered: {len(skills)}")
        
        for skill in skills:
            print(f"   â€¢ {skill.name} ({skill.id}) âœ…")
        
        # Test executor initialization
        executor = InfrastructureMonitoringExecutor()
        if hasattr(executor, 'agent') and hasattr(executor, 'metrics'):
            print("âœ… Executor properly initialized with agent and metrics")
        else:
            print("âŒ Executor missing required components")
            return False
        
        return True
        
    except Exception as e:
        print(f"âŒ Agent initialization failed: {e}")
        return False


async def test_monitoring_capabilities():
    """Test 2: Core Infrastructure Monitoring"""
    print("\nğŸ—ï¸ Test 2: Core Infrastructure Monitoring...")
    
    try:
        from multi_agent_a2a.agents.infrastructure_monitor.agent import InfrastructureMonitoringAgent
        
        agent = InfrastructureMonitoringAgent()
        
        # Test infrastructure monitoring
        print("   Testing infrastructure monitoring...")
        monitoring_request = {
            'services': ['web_frontend', 'database_primary', 'cache_layer'],
            'include_recommendations': True
        }
        
        status = await agent.monitor_infrastructure(monitoring_request, "test_context")
        
        print(f"   âœ… Overall Health: {status.overall_health.value}")
        print(f"   âœ… Services Monitored: {status.services_monitored}")
        print(f"   âœ… Active Alerts: {status.active_alerts}")
        print(f"   âœ… Anomalies Detected: {len(status.anomalies_detected)}")
        print(f"   âœ… Failure Predictions: {len(status.failure_predictions)}")
        print(f"   âœ… Performance Insights: {len(status.performance_insights)}")
        print(f"   âœ… Recommendations: {len(status.optimization_recommendations)}")
        
        # Test streaming responses
        print("   Testing streaming responses...")
        stream_count = 0
        async for response in agent.stream("Monitor infrastructure health", "test_stream"):
            if response.get('content') and len(response['content']) > 50:
                print(f"   âœ… Streaming response received (length: {len(response['content'])})")
                stream_count += 1
                if response.get('is_task_complete'):
                    break
        
        print(f"   âœ… Streaming responses: {stream_count}")
        
        return True
        
    except Exception as e:
        print(f"   âŒ Monitoring capabilities test failed: {e}")
        return False


async def test_anomaly_detection():
    """Test 3: AI-Ops Anomaly Detection"""
    print("\nğŸš¨ Test 3: AI-Ops Anomaly Detection...")
    
    try:
        from multi_agent_a2a.agents.infrastructure_monitor.agent import InfrastructureMonitoringAgent
        
        agent = InfrastructureMonitoringAgent()
        
        # Test anomaly detection
        print("   Testing AI-powered anomaly detection...")
        anomalies = await agent._detect_anomalies()
        
        print(f"   âœ… Anomaly detection algorithm executed successfully")
        print(f"   âœ… Anomalies detected: {len(anomalies)}")
        
        for anomaly in anomalies[:3]:  # Show first 3
            print(f"      â€¢ Service: {anomaly.service_name}")
            print(f"        Type: {anomaly.anomaly_type}")
            print(f"        Severity: {anomaly.severity.value}")
            print(f"        Confidence: {anomaly.confidence_score:.1%}")
            print(f"        Recommendations: {len(anomaly.recommendations)}")
        
        # Test anomaly query processing
        print("   Testing anomaly detection queries...")
        async for response in agent.stream("Detect anomalies in the infrastructure", "anomaly_test"):
            if response.get('is_task_complete'):
                content = response.get('content', '')
                if 'anomaly' in content.lower() or 'analysis' in content.lower():
                    print(f"   âœ… Anomaly analysis response generated (length: {len(content)})")
                break
        
        return True
        
    except Exception as e:
        print(f"   âŒ Anomaly detection test failed: {e}")
        return False


async def test_failure_prediction():
    """Test 4: Predictive Failure Analysis"""
    print("\nğŸ”® Test 4: Predictive Failure Analysis...")
    
    try:
        from multi_agent_a2a.agents.infrastructure_monitor.agent import InfrastructureMonitoringAgent
        
        agent = InfrastructureMonitoringAgent()
        
        # Test failure prediction
        print("   Testing AI-powered failure prediction...")
        predictions = await agent._predict_failures()
        
        print(f"   âœ… Prediction model executed successfully")
        print(f"   âœ… Failure predictions: {len(predictions)}")
        print(f"   âœ… Model accuracy: {agent.prediction_model_accuracy:.1%}")
        
        for prediction in predictions[:2]:  # Show first 2
            print(f"      â€¢ Service: {prediction.service_name}")
            print(f"        Failure Type: {prediction.failure_type}")
            print(f"        Probability: {prediction.probability:.1%}")
            print(f"        Leading Indicators: {len(prediction.leading_indicators)}")
            print(f"        Mitigation Steps: {len(prediction.mitigation_steps)}")
        
        # Test prediction query processing
        print("   Testing failure prediction queries...")
        async for response in agent.stream("Predict potential system failures", "prediction_test"):
            if response.get('is_task_complete'):
                content = response.get('content', '')
                if 'prediction' in content.lower() or 'failure' in content.lower():
                    print(f"   âœ… Prediction analysis response generated (length: {len(content)})")
                break
        
        return True
        
    except Exception as e:
        print(f"   âŒ Failure prediction test failed: {e}")
        return False


async def test_query_processing():
    """Test 5: Query Processing and Response Generation"""
    print("\nğŸ’¬ Test 5: Query Processing and Response Generation...")
    
    try:
        from multi_agent_a2a.agents.infrastructure_monitor.agent import InfrastructureMonitoringAgent
        
        agent = InfrastructureMonitoringAgent()
        
        test_queries = [
            ("Monitor infrastructure health and performance", "monitor_infrastructure"),
            ("Detect anomalies in system behavior", "detect_anomalies"),
            ("Predict potential failures", "predict_failures"),
            ("What infrastructure monitoring capabilities do you have?", "monitor_infrastructure")
        ]
        
        for query, expected_skill in test_queries:
            print(f"   Testing: '{query[:50]}...'")
            
            skill = agent._determine_skill_from_query(query)
            if skill == expected_skill or expected_skill == "general":
                print(f"      âœ… Skill detected: {skill}")
            else:
                print(f"      âš ï¸  Expected {expected_skill}, got {skill}")
            
            # Test response generation
            async for response in agent.stream(query, "test_context"):
                if response.get('content') and len(response['content']) > 50:
                    print(f"      âœ… Response generated (length: {len(response['content'])})")
                    break
        
        return True
        
    except Exception as e:
        print(f"   âŒ Query processing test failed: {e}")
        return False


async def test_ai_ops_integration():
    """Test 6: AI-Ops Integration and Intelligence"""
    print("\nğŸ¤– Test 6: AI-Ops Integration and Intelligence...")
    
    try:
        from multi_agent_a2a.agents.infrastructure_monitor.agent import InfrastructureMonitoringAgent
        
        agent = InfrastructureMonitoringAgent()
        
        # Test AI-Ops capabilities
        print("   Testing service provider database...")
        if len(agent.monitored_services) >= 6:
            print(f"   âœ… Monitoring {len(agent.monitored_services)} services")
            
            # Check service details
            for service_id, service_data in list(agent.monitored_services.items())[:3]:
                print(f"      â€¢ {service_data['name']}: {service_data['status'].value}")
        else:
            print(f"   âŒ Insufficient monitored services: {len(agent.monitored_services)}")
            return False
        
        # Test insights generation
        print("   Testing performance insights generation...")
        insights = agent._generate_performance_insights()
        if len(insights) >= 3:
            print(f"   âœ… Generated {len(insights)} performance insights")
        else:
            print(f"   âŒ Insufficient insights generated: {len(insights)}")
            return False
        
        # Test optimization recommendations
        print("   Testing optimization recommendations...")
        recommendations = agent._generate_optimization_recommendations()
        if len(recommendations) >= 3:
            print(f"   âœ… Generated {len(recommendations)} optimization recommendations")
        else:
            print(f"   âŒ Insufficient recommendations: {len(recommendations)}")
            return False
        
        # Test overall health calculation
        print("   Testing overall health calculation...")
        health = agent._calculate_overall_health()
        print(f"   âœ… Overall health status: {health.value}")
        
        # Test metrics tracking
        print("   Testing metrics tracking...")
        agent.metrics.track_simple_operation("test_operation")
        print("   âœ… Metrics tracking functional")
        
        return True
        
    except Exception as e:
        print(f"   âŒ AI-Ops integration test failed: {e}")
        return False


async def test_production_readiness():
    """Test 7: Production Readiness Features"""
    print("\nğŸš€ Test 7: Production Readiness Features...")
    
    try:
        from multi_agent_a2a.agents.infrastructure_monitor.agent import InfrastructureMonitoringAgent, InfrastructureMonitoringExecutor
        
        # Test agent features
        agent = InfrastructureMonitoringAgent()
        
        # Test error handling
        print("   Testing error handling...")
        try:
            invalid_request = {'invalid': 'data'}
            status = await agent.monitor_infrastructure(invalid_request, "error_test")
            if status and status.services_monitored > 0:
                print("   âœ… Graceful error handling with defaults")
            else:
                print("   âŒ Error handling failed")
                return False
        except Exception as e:
            print(f"   âŒ Error handling threw exception: {e}")
            return False
        
        # Test logging
        print("   Testing logging...")
        if hasattr(agent, 'logger'):
            print("   âœ… Logger configured")
        else:
            print("   âŒ Logger missing")
            return False
        
        # Test metrics
        print("   Testing metrics integration...")
        if hasattr(agent, 'metrics'):
            print("   âœ… Metrics integration working")
        else:
            print("   âŒ Metrics integration missing")
            return False
        
        # Test executor
        print("   Testing executor configuration...")
        executor = InfrastructureMonitoringExecutor()
        if hasattr(executor, 'agent') and hasattr(executor, 'execute') and hasattr(executor, 'cancel'):
            print("   âœ… Executor properly configured")
        else:
            print("   âŒ Executor missing required methods")
            return False
        
        # Test state management
        print("   Testing state management...")
        if hasattr(agent, 'active_alerts') and hasattr(agent, 'monitored_services'):
            print(f"   âœ… State management: {len(agent.active_alerts)} alerts, {len(agent.monitored_services)} services")
        else:
            print("   âŒ State management missing")
            return False
        
        return True
        
    except Exception as e:
        print(f"   âŒ Production readiness test failed: {e}")
        return False


async def main():
    """Run all tests and generate summary report."""
    print("ğŸ—ï¸ Testing Infrastructure Monitoring Agent for Production AI-Ops")
    print("ğŸ¯ Focus: Anomaly detection and predictive analytics")
    
    tests = [
        ("Agent Initialization", test_agent_initialization),
        ("Monitoring Capabilities", test_monitoring_capabilities),
        ("Anomaly Detection", test_anomaly_detection),
        ("Failure Prediction", test_failure_prediction),
        ("Query Processing", test_query_processing),
        ("AI-Ops Integration", test_ai_ops_integration),
        ("Production Readiness", test_production_readiness)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        print(f"\n{'='*60}")
        try:
            result = await test_func()
            results.append((test_name, result))
            if result:
                print(f"âœ… {test_name}: PASSED")
            else:
                print(f"âŒ {test_name}: FAILED")
        except Exception as e:
            print(f"âŒ {test_name}: ERROR - {e}")
            results.append((test_name, False))
    
    # Generate summary report
    print(f"\n{'='*60}")
    print("ğŸ“Š INFRASTRUCTURE MONITORING AGENT - TEST SUMMARY")
    print("="*60)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for test_name, result in results:
        status = "âœ… PASSED" if result else "âŒ FAILED"
        print(f"{test_name:.<30} {status}")
    
    print(f"\nğŸ¯ Overall Results: {passed}/{total} tests passed ({passed/total:.1%})")
    
    if passed == total:
        print("\nğŸš€ INFRASTRUCTURE MONITORING AGENT READY FOR PRODUCTION!")
        print("ğŸ—ï¸ All AI-Ops capabilities verified for production deployment")
        print("ğŸ“Š Agent ready for A2A communication on port 8005")
        print("ğŸ” Advanced monitoring with anomaly detection operational")
        return True
    else:
        print(f"\nâš ï¸  {total-passed} tests failed - review before production deployment")
        return False


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)